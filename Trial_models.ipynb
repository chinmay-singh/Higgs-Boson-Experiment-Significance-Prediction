{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, tpe, STATUS_OK, Trials\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ams(s, b):\n",
    "    return math.sqrt(2 * ((s + b + 10) * math.log(1.0 + s/(b + 10)) - s))\n",
    "\n",
    "def get_ams_score(W, Y, Y_pred):\n",
    "    s = W * (Y == 1) * (Y_pred == 1)\n",
    "    b = W * (Y == 0) * (Y_pred == 1)\n",
    "    s = np.sum(s)\n",
    "    b = np.sum(b)\n",
    "    return ams(s, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBClassifier(n_estimators =400,colsample_bytree=0.9898730781107081,\n",
    "                           learning_rate =0.75,\n",
    "                            max_depth = 12,\n",
    "                            min_child_weight = 8,\n",
    "                            subsample = 0.7835130878302855 ,\n",
    "                           gamma = 0.20827377476218553,\n",
    "                           reg_lambda = 0.12391233401791746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X, X_test):\n",
    "    imputer = Imputer(missing_values = -999.0, strategy = 'most_frequent')\n",
    "    X = imputer.fit_transform(X)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    inv_log_cols = (0,1,2,3,4,5,7,8,9,10,12,13,16,19,21,23,26)\n",
    "    X_inv_log_cols = np.log(1 / (1 + X[:, inv_log_cols]))\n",
    "    X = np.hstack((X, X_inv_log_cols))\n",
    "    X_test_inv_log_cols = np.log(1 / (1 + X_test[:, inv_log_cols]))\n",
    "    X_test = np.hstack((X_test, X_test_inv_log_cols))\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model():\n",
    "    classifier = xgb.XGBClassifier(n_estimators =400,colsample_bytree=0.7164544506182514,\n",
    "                           learning_rate =0.6386564262937965,\n",
    "                            max_depth = 6,\n",
    "                            min_child_weight = 9,\n",
    "                            subsample = 0.7423464990361603,\n",
    "                           gamma = 0.20827377476218553,\n",
    "                           reg_lambda = 0.3932413651019372)\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'learning_rate': 0.6386564262937965, 'x_colsample_bytree': 0.7164544506182514, 'x_gamma': 0.1257948856159213, 'x_max_depth': 6.0, 'x_min_child': 9.0, 'x_reg_lambda': 0.3932413651019372, 'x_subsample': 0.7423464990361603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(X, W, Y, X_test):\n",
    "    X, X_test = preprocess(X, X_test)\n",
    "    classifier = single_model()\n",
    "    classifier.fit(X, Y, sample_weight = W)\n",
    "    Y_pred = classifier.predict_proba(X)[:,1]\n",
    "    Y_test_pred = classifier.predict_proba(X_test)[:,1]\n",
    "    signal_threshold = 83\n",
    "    cut = np.percentile(Y_test_pred, signal_threshold)\n",
    "    thresholded_Y_pred = Y_pred > cut\n",
    "    thresholded_Y_test_pred = Y_test_pred > cut\n",
    "    \n",
    "    return [Y_test_pred, thresholded_Y_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(ids_test, Y_test_pred, thresholded_Y_test_pred):\n",
    "    ids_probs = np.transpose(np.vstack((ids_test, Y_test_pred)))\n",
    "    ids_probs = np.array(sorted(ids_probs, key = lambda x: -x[1]))\n",
    "    ids_probs_ranks = np.hstack((\n",
    "        ids_probs,\n",
    "        np.arange(1, ids_probs.shape[0]+1).reshape((ids_probs.shape[0], 1))))\n",
    "\n",
    "    test_ids_map = {}\n",
    "    for test_id, prob, rank in ids_probs_ranks:\n",
    "        test_id = int(test_id)\n",
    "        rank = int(rank)\n",
    "        test_ids_map[test_id] = rank\n",
    "\n",
    "    f = open('submission2.csv', 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['EventId', 'RankOrder', 'Class'])\n",
    "    for i, pred in enumerate(thresholded_Y_test_pred):\n",
    "        event_id = int(ids_test[i])\n",
    "        rank = test_ids_map[ids_test[i]]\n",
    "        klass = pred and 's' or 'b'\n",
    "        writer.writerow([event_id, rank, klass])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data.\n",
      "Loading testing data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('Loading training data.')\n",
    "data = np.loadtxt('training.csv',delimiter=',',skiprows=1, converters={32: lambda x:int(x=='s'.encode('utf-8'))})\n",
    "\n",
    "X = data[:,1:31]\n",
    "Y = data[:,32]\n",
    "W = data[:,31]\n",
    "\n",
    "print ('Loading testing data.')\n",
    "test_data = np.loadtxt('test.csv',delimiter=',', skiprows=1)\n",
    "\n",
    "ids_test = test_data[:,0]\n",
    "X_test = test_data[:,1:31]\n",
    "W = data[:,31]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X, X_test = preprocess(X, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train,y_test= train_test_split(\n",
    "        X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28054.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_train = W[0:167500] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167500"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82500"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_test = W[167500:(167500+82500)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167500"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)/len(y_train\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00265331, 2.23358449, 2.34738894, ..., 0.74405625, 0.01863612,\n",
       "       0.74405625])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "    signal_threshold = 83\n",
    "    cut = np.percentile(y_test, signal_threshold)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_Y_test_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y_test:\n",
    "    if i > cut:\n",
    "        thresholded_Y_test_pred.append(1)\n",
    "    else:\n",
    "        thresholded_Y_test_pred.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = thresholded_Y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(thresholded_Y_test_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0303030303030303"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_train)/len(w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ams(s, b):\n",
    "    return math.sqrt(2 * ((s + b + 10) * math.log(1.0 + s/(b + 10)) - s))\n",
    "\n",
    "def get_ams_score(W, Y, Y_pred):\n",
    "    s = W * (Y == 1) * (Y_pred == 1)\n",
    "    b = W * (Y == 0) * (Y_pred == 1)\n",
    "    s = np.sum(s)\n",
    "    print(np.sum(s))\n",
    "    b = np.sum(b)\n",
    "    print(np.sum(b))\n",
    "    return ams(s, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57613"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.9768662 , 0.8631929 , 4.48227795, ..., 0.01863612, 1.68161144,\n",
       "       1.87747381])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9510186275634118, 'gamma': 0.18680387090667083, 'learning_rate': 0.7760190514338368, 'max_depth': 7.0, 'min_child_weight': 3.0, 'reg_lambda': 0.2260143374973682, 'subsample': 0.746885102953742}\n",
      "1\n",
      "3\n",
      "4429\n",
      "2\n",
      "SCORE: 0.05368484848484849\n",
      "{'colsample_bytree': 0.8885297557806396, 'gamma': 0.36980940844416743, 'learning_rate': 0.6978245494137797, 'max_depth': 13.0, 'min_child_weight': 3.0, 'reg_lambda': 0.5801079375774624, 'subsample': 0.894974056326531}\n",
      "1\n",
      "3\n",
      "14011\n",
      "2\n",
      "SCORE: 0.16983030303030303\n",
      "{'colsample_bytree': 0.893191652048703, 'gamma': 0.6665868045305081, 'learning_rate': 0.5598442346213914, 'max_depth': 13.0, 'min_child_weight': 2.0, 'reg_lambda': 0.6679417184820324, 'subsample': 0.8423929631697443}\n",
      "1\n",
      "3\n",
      "13880\n",
      "2\n",
      "SCORE: 0.16824242424242425\n",
      "{'colsample_bytree': 0.96307631811762, 'gamma': 0.3429963879608512, 'learning_rate': 0.6176082815840426, 'max_depth': 11.0, 'min_child_weight': 4.0, 'reg_lambda': 0.3490315065026057, 'subsample': 0.9492488971963139}\n",
      "1\n",
      "3\n",
      "14023\n",
      "2\n",
      "SCORE: 0.16997575757575759\n",
      "{'colsample_bytree': 0.8167958743576358, 'gamma': 0.40006868367214465, 'learning_rate': 0.6648925912743143, 'max_depth': 9.0, 'min_child_weight': 6.0, 'reg_lambda': 0.281445176263154, 'subsample': 0.8391930225580629}\n",
      "1\n",
      "3\n",
      "13619\n",
      "2\n",
      "SCORE: 0.16507878787878788\n",
      "{'colsample_bytree': 0.8956849047204393, 'gamma': 0.2553068567874705, 'learning_rate': 0.5301446213492564, 'max_depth': 14.0, 'min_child_weight': 6.0, 'reg_lambda': 0.6634835729799594, 'subsample': 0.9294253623900103}\n",
      "1\n",
      "3\n",
      "14003\n",
      "2\n",
      "SCORE: 0.16973333333333335\n",
      "{'colsample_bytree': 0.9315168405938927, 'gamma': 0.68133187610393, 'learning_rate': 0.5128104974033564, 'max_depth': 14.0, 'min_child_weight': 6.0, 'reg_lambda': 0.7221690440512966, 'subsample': 0.756205010570979}\n",
      "1\n",
      "3\n",
      "13975\n",
      "2\n",
      "SCORE: 0.1693939393939394\n",
      "{'colsample_bytree': 0.738010036700728, 'gamma': 0.3220619161735533, 'learning_rate': 0.6922761507598969, 'max_depth': 5.0, 'min_child_weight': 3.0, 'reg_lambda': 0.7846021745439903, 'subsample': 0.7965406159473062}\n",
      "1\n",
      "3\n",
      "12996\n",
      "2\n",
      "SCORE: 0.15752727272727274\n",
      "{'colsample_bytree': 0.9255997751505712, 'gamma': 0.6924779687740933, 'learning_rate': 0.5924208315356814, 'max_depth': 5.0, 'min_child_weight': 3.0, 'reg_lambda': 0.30244903670137324, 'subsample': 0.9417512398522055}\n",
      "1\n",
      "3\n",
      "13421\n",
      "2\n",
      "SCORE: 0.16267878787878787\n",
      "{'colsample_bytree': 0.9098100432643363, 'gamma': 0.5601445430209663, 'learning_rate': 0.6362179902795656, 'max_depth': 12.0, 'min_child_weight': 3.0, 'reg_lambda': 0.7838071506921143, 'subsample': 0.8338610400085422}\n",
      "1\n",
      "3\n",
      "13372\n",
      "2\n",
      "SCORE: 0.1620848484848485\n",
      "{'colsample_bytree': 0.8399882069378091, 'gamma': 0.10050145015273804, 'learning_rate': 0.7751069575249803, 'max_depth': 14.0, 'min_child_weight': 4.0, 'reg_lambda': 0.2789615017717193, 'subsample': 0.8883240489987327}\n",
      "1\n",
      "3\n",
      "13236\n",
      "2\n",
      "SCORE: 0.16043636363636363\n",
      "{'colsample_bytree': 0.8339233725971049, 'gamma': 0.31932357218076957, 'learning_rate': 0.668966566244839, 'max_depth': 8.0, 'min_child_weight': 4.0, 'reg_lambda': 0.7006570482398502, 'subsample': 0.7462344547171278}\n",
      "1\n",
      "3\n",
      "13486\n",
      "2\n",
      "SCORE: 0.16346666666666668\n",
      "{'colsample_bytree': 0.9663909611167854, 'gamma': 0.30555698176562146, 'learning_rate': 0.5834540400158387, 'max_depth': 11.0, 'min_child_weight': 5.0, 'reg_lambda': 0.8274421878931161, 'subsample': 0.7305490861001825}\n",
      "1\n",
      "3\n",
      "13719\n",
      "2\n",
      "SCORE: 0.1662909090909091\n",
      "{'colsample_bytree': 0.7938547413226976, 'gamma': 0.4568010978889002, 'learning_rate': 0.590235559185034, 'max_depth': 12.0, 'min_child_weight': 9.0, 'reg_lambda': 0.13939681166788354, 'subsample': 0.9179284237570922}\n",
      "1\n",
      "3\n",
      "13871\n",
      "2\n",
      "SCORE: 0.16813333333333333\n",
      "{'colsample_bytree': 0.708165777404497, 'gamma': 0.5046964264699333, 'learning_rate': 0.5477772486255414, 'max_depth': 8.0, 'min_child_weight': 7.0, 'reg_lambda': 0.575866748378799, 'subsample': 0.9239404518726564}\n",
      "1\n",
      "3\n",
      "13941\n",
      "2\n",
      "SCORE: 0.16898181818181818\n",
      "{'colsample_bytree': 0.8312863353174309, 'gamma': 0.3631565288981403, 'learning_rate': 0.5629324371208004, 'max_depth': 13.0, 'min_child_weight': 7.0, 'reg_lambda': 0.9231433273192604, 'subsample': 0.9666472514165352}\n",
      "1\n",
      "3\n",
      "14025\n",
      "2\n",
      "SCORE: 0.17\n",
      "{'colsample_bytree': 0.8661834829577155, 'gamma': 0.6605137689210797, 'learning_rate': 0.5690892518366395, 'max_depth': 11.0, 'min_child_weight': 6.0, 'reg_lambda': 0.9433960435525134, 'subsample': 0.7476620262756498}\n",
      "1\n",
      "3\n",
      "13952\n",
      "2\n",
      "SCORE: 0.16911515151515152\n",
      "{'colsample_bytree': 0.9832852958053213, 'gamma': 0.6037298574799032, 'learning_rate': 0.538190963833075, 'max_depth': 9.0, 'min_child_weight': 7.0, 'reg_lambda': 0.7910154725051379, 'subsample': 0.8738597031352484}\n",
      "1\n",
      "3\n",
      "13761\n",
      "2\n",
      "SCORE: 0.1668\n",
      "{'colsample_bytree': 0.7589256429150549, 'gamma': 0.5562969122760046, 'learning_rate': 0.5179382954214903, 'max_depth': 8.0, 'min_child_weight': 10.0, 'reg_lambda': 0.5578875599398104, 'subsample': 0.71136602736678}\n",
      "1\n",
      "3\n",
      "13950\n",
      "2\n",
      "SCORE: 0.1690909090909091\n",
      "{'colsample_bytree': 0.7164544506182514, 'gamma': 0.1257948856159213, 'learning_rate': 0.6386564262937965, 'max_depth': 6.0, 'min_child_weight': 9.0, 'reg_lambda': 0.3932413651019372, 'subsample': 0.7423464990361603}\n",
      "1\n",
      "3\n",
      "2299\n",
      "2\n",
      "SCORE: 0.027866666666666668\n",
      "{'learning_rate': 0.6386564262937965, 'x_colsample_bytree': 0.7164544506182514, 'x_gamma': 0.1257948856159213, 'x_max_depth': 6.0, 'x_min_child': 9.0, 'x_reg_lambda': 0.3932413651019372, 'x_subsample': 0.7423464990361603}\n",
      "{'learning_rate': 0.6386564262937965, 'x_colsample_bytree': 0.7164544506182514, 'x_gamma': 0.1257948856159213, 'x_max_depth': 6.0, 'x_min_child': 9.0, 'x_reg_lambda': 0.3932413651019372, 'x_subsample': 0.7423464990361603}\n"
     ]
    }
   ],
   "source": [
    "def objective(space):\n",
    "    print(space)\n",
    "    clf = xgb.XGBClassifier(n_estimators = 400,colsample_bytree=space['colsample_bytree'],\n",
    "                           learning_rate = space['learning_rate'],\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                           gamma = space['gamma'],\n",
    "                           reg_lambda = space['reg_lambda'],)\n",
    "    \n",
    "    eval_set  = [( X_train, y_train),(X_test, y_test)]\n",
    "    print('1')\n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=eval_set,sample_weight=w_train, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    print('3')\n",
    "    pred = clf.predict_proba(X_test)[:,1]\n",
    "    signal_threshold = 83\n",
    "    cut = np.percentile(pred, signal_threshold)\n",
    "    thresholded_Y_test_pred = []\n",
    "    for i in pred:\n",
    "        if i > cut:\n",
    "            thresholded_Y_test_pred.append(1)\n",
    "        else:\n",
    "            thresholded_Y_test_pred.append(0)\n",
    "    \n",
    "    print(np.sum(thresholded_Y_test_pred))\n",
    "#     y_test_pred, pred = train_and_predict(X, W, Y, X_test)\n",
    "#     clf.fit()\n",
    "#     pred = clf.predict(X_test)\n",
    "    print('2')\n",
    "    mae = mean_absolute_error((y_test), (thresholded_Y_test_pred))\n",
    "#     ams_score = get_ams_score(w_test,y_test, thresholded_Y_test_pred)\n",
    "    print (\"SCORE:\", mae)\n",
    "    #change the metric if you like\n",
    "    return {'loss':mae, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "space ={'max_depth': hp.quniform(\"x_max_depth\", 4, 16, 1),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.7, 1),\n",
    "        'gamma' : hp.uniform ('x_gamma', 0.1,0.7),\n",
    "        'learning_rate': hp.uniform('learning_rate',0.5,0.8),\n",
    "        'colsample_bytree' : hp.uniform ('x_colsample_bytree', 0.7,1),\n",
    "        'reg_lambda' : hp.uniform ('x_reg_lambda', 0,1)\n",
    "    }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)\n",
    "\n",
    "#{'x_colsample_bytree': 0.9859833603957928, 'x_gamma': 0.4881540428925282, 'x_max_depth': 4.0, 'x_min_child': 4.0, 'x_reg_lambda': 0.9983795315029678, 'x_subsample': 0.9547128225167194}\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.6386564262937965, 'x_colsample_bytree': 0.7164544506182514, 'x_gamma': 0.1257948856159213, 'x_max_depth': 6.0, 'x_min_child': 9.0, 'x_reg_lambda': 0.3932413651019372, 'x_subsample': 0.7423464990361603}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train model now. \n",
    "\n",
    "Y_test_pred, thresholded_Y_test_pred = train_and_predict(X, W, Y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unique'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3e29f36fc9ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mthresholded_Y_test_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unique'"
     ]
    }
   ],
   "source": [
    "thresholded_Y_test_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission(ids_test, Y_test_pred, thresholded_Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82500"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thresholded_Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC\n",
    "# from sknn import mlp\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n"
     ]
    }
   ],
   "source": [
    "# Load traning data:\n",
    "print ('Loading Data')\n",
    "n_skiprows = 1\n",
    "data_train = np.loadtxt('training.csv', delimiter=',', skiprows=n_skiprows, converters={32: lambda x:int(x=='s'.encode('utf-8'))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "r = np.random.rand(data_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning data to numpy arrays\n",
      "Training classifier ...\n",
      "Computing AMS score\n",
      "AMS of training set (90%):  14.242369543157219\n",
      "AMS of validation set (10%):  3.1563058348298925\n",
      "Computing Percentage Error\n",
      "Generalization Error Too Big\n",
      "Loading test data\n",
      "Making predictions for test data\n",
      "Organizing the prediction results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:117: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CSV file for Kaggle Submission\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print ('Assigning data to numpy arrays')\n",
    "cv_ratio = 0.75\n",
    "Y_train = data_train[:,32][r<cv_ratio] > 0.\n",
    "X_train = data_train[:,1:31][r<cv_ratio]\n",
    "W_train = data_train[:,31][r<cv_ratio]\n",
    "Y_valid = data_train[:,32][r>=cv_ratio] > 0.\n",
    "X_valid = data_train[:,1:31][r>=cv_ratio]\n",
    "W_valid = data_train[:,31][r>=cv_ratio]\n",
    "\n",
    "print ('Training classifier ...')\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_estimators =400,colsample_bytree=0.7164544506182514,\n",
    "                           learning_rate =0.6386564262937965,\n",
    "                            max_depth = 6,\n",
    "                            min_child_weight = 9,\n",
    "                            subsample = 0.7423464990361603,\n",
    "                           gamma = 0.20827377476218553,\n",
    "                           reg_lambda = 0.3932413651019372)\n",
    "xgb_model.fit(X_train, Y_train, sample_weight=W_train)\n",
    "\n",
    "prob_predict_train = xgb_model.predict_proba(X_train)[:,1]\n",
    "prob_predict_valid = xgb_model.predict_proba(X_valid)[:,1]\n",
    "\n",
    "pcut = np.percentile(prob_predict_train, 85)\n",
    "\n",
    "Yhat_train = prob_predict_train > pcut\n",
    "Yhat_valid = prob_predict_valid > pcut\n",
    "\n",
    "true_positive_train = W_train * (Y_train == 1.0) * (1.0/cv_ratio)\n",
    "true_negative_train = W_train * (Y_train == 0.0) * (1.0/cv_ratio)\n",
    "true_positive_valid = W_valid * (Y_valid == 1.0) * (1.0/(1-cv_ratio))\n",
    "true_negative_valid = W_valid * (Y_valid == 0.0) * (1.0/(1-cv_ratio))\n",
    "\n",
    "s_train = sum ( true_positive_train * (Yhat_train == 1.0) )\n",
    "b_train = sum ( true_negative_train * (Yhat_train == 1.0) )\n",
    "s_valid = sum ( true_positive_valid * (Yhat_valid == 1.0) )\n",
    "b_valid = sum ( true_negative_valid * (Yhat_valid == 1.0) )\n",
    " \n",
    "print ('Computing AMS score')\n",
    "def AMSScore(s,b):\n",
    "    return math.sqrt (2.*( (s + b + 10.) * math.log(1. + s / (b + 10.)) - s))\n",
    "\n",
    "ams_train = AMSScore(s_train, b_train)\n",
    "ams_valid = AMSScore(s_valid, b_valid)\n",
    "\n",
    "print ('AMS of training set (90%): ', ams_train)\n",
    "print ('AMS of validation set (10%): ', ams_valid)\n",
    "\n",
    "# Compute Percent Error training and validation set:\n",
    "print ('Computing Percentage Error')\n",
    "predict_train = xgb_model.predict(X_train)\n",
    "predict_valid = xgb_model.predict(X_valid)\n",
    "\n",
    "epsilon_error = 0.45\n",
    "if abs(ams_train - ams_valid) > epsilon_error:\n",
    "    print ('Generalization Error Too Big')\n",
    "\n",
    "\n",
    "print ('Loading test data')\n",
    "data_test = np.loadtxt('test.csv', delimiter=',', skiprows=1)\n",
    "X_test = data_test[:,1:31]\n",
    "ID_test = list(data_test[:,0])\n",
    "\n",
    "print ('Making predictions for test data')\n",
    "prob_predict_test = xgb_model.predict_proba(X_test)[:,1]\n",
    "Yhat_test = list(prob_predict_test > pcut)\n",
    "prob_predict_test = list(prob_predict_test)\n",
    "\n",
    "print ('Organizing the prediction results')\n",
    "result_list = []\n",
    "for x in range(len(ID_test)):\n",
    "\tresult_list.append([int(ID_test[x]), prob_predict_test[x], 's'*(Yhat_test[x]==1.0)+'b'*(Yhat_test[x]==0.0)])\n",
    "\n",
    "result_list = sorted(result_list, key=lambda a_entry: a_entry[1])\n",
    "\n",
    "for y in range(len(result_list)):\n",
    "    result_list[y][1] = y+1\n",
    "\n",
    "result_list = sorted(result_list, key=lambda a_entry: a_entry[0])\n",
    "\n",
    "print ('Writing CSV file for Kaggle Submission')\n",
    "fcsv = open('higgsml_output2.csv', 'w')\n",
    "fcsv.write('EventId,RankOrder,Class\\n')\n",
    "for line in result_list:\n",
    "    the_line = str(line[0]) + ',' + str(line[1]) + ',' + line[2] + '\\n'\n",
    "    fcsv.write(the_line);\n",
    "fcsv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(df.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = df.replace(-999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df , columns = ['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ams(s, b):\n",
    "    return math.sqrt(2 * ((s + b + 10) * math.log(1.0 + s/(b + 10)) - s))\n",
    "\n",
    "def get_ams_score(W, Y, Y_pred):\n",
    "    s = W * (Y == 1) * (Y_pred == 1)\n",
    "    b = W * (Y == 0) * (Y_pred == 1)\n",
    "    s = np.sum(s)\n",
    "    b = np.sum(b)\n",
    "    return ams(s, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Label_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    print(space)\n",
    "    clf = xgb.XGBClassifier(n_estimators =1000,colsample_bytree=space['colsample_bytree'],\n",
    "                           learning_rate = space['learning_rate'],\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                           gamma = space['gamma'],\n",
    "                           reg_lambda = space['reg_lambda'],)\n",
    "\n",
    "    eval_set  = [( X_train, y_train),(X_test, y_test)]\n",
    "\n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    mse_scr = mean_squared_error(y_test, pred)\n",
    "    print (\"SCORE:\", np.sqrt(mse_scr))\n",
    "    #change the metric if you like\n",
    "    return {'loss':mse_scr, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "space ={'max_depth': hp.quniform(\"x_max_depth\", 4, 16, 1),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.7, 1),\n",
    "        'gamma' : hp.uniform ('x_gamma', 0.1,0.7),\n",
    "        'learning_rate': hp.uniform('learning_rate',0.05,0.4),\n",
    "        'colsample_bytree' : hp.uniform ('x_colsample_bytree', 0.7,1),\n",
    "        'reg_lambda' : hp.uniform ('x_reg_lambda', 0,1)\n",
    "    }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)\n",
    "\n",
    "#{'x_colsample_bytree': 0.9859833603957928, 'x_gamma': 0.4881540428925282, 'x_max_depth': 4.0, 'x_min_child': 4.0, 'x_reg_lambda': 0.9983795315029678, 'x_subsample': 0.9547128225167194}\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = xgb.XGBRegressor(n_estimators =1000,colsample_bytree=0.9898730781107081,\n",
    "                           learning_rate =0.37726772129255276,\n",
    "                            max_depth = 8,\n",
    "                            min_child_weight = 8,\n",
    "                            subsample = 0.7835130878302855 ,\n",
    "                           gamma = 0.20827377476218553,\n",
    "                           reg_lambda = 0.12391233401791746)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = X.Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_new,y,sample_weight = weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_modelhiggs.sav'\n",
    "pickle.dump(model1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.replace(-999, np.nan)\n",
    "\n",
    "df2 = df2.replace(999, np.nan)\n",
    "\n",
    "df2 = df2.fillna(df2.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df2.iloc[:,1:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(pred)a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.replace(0,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    print(space)\n",
    "    clf = xgb.XGBRegressor(n_estimators =1000,colsample_bytree=space['colsample_bytree'],\n",
    "                           learning_rate = space['learning_rate'],\n",
    "                            max_depth = int(space['max_depth']),\n",
    "                            min_child_weight = space['min_child_weight'],\n",
    "                            subsample = space['subsample'],\n",
    "                           gamma = space['gamma'],\n",
    "                           reg_lambda = space['reg_lambda'],)\n",
    "\n",
    "    eval_set  = [( X_train, y_train),(X_test, y_test)]\n",
    "\n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=eval_set, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    mse_scr = mean_squared_error(y_test, pred)\n",
    "    print (\"SCORE:\", np.sqrt(mse_scr))\n",
    "    #change the metric if you like\n",
    "    return {'loss':mse_scr, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "space ={'max_depth': hp.quniform(\"x_max_depth\", 4, 16, 1),\n",
    "        'min_child_weight': hp.quniform ('x_min_child', 1, 10, 1),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.7, 1),\n",
    "        'gamma' : hp.uniform ('x_gamma', 0.1,0.7),\n",
    "        'learning_rate': hp.uniform('learning_rate',0.05,0.4),\n",
    "        'colsample_bytree' : hp.uniform ('x_colsample_bytree', 0.7,1),\n",
    "        'reg_lambda' : hp.uniform ('x_reg_lambda', 0,1)\n",
    "    }\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,\n",
    "            trials=trials)\n",
    "\n",
    "print(best)\n",
    "\n",
    "#{'x_colsample_bytree': 0.9859833603957928, 'x_gamma': 0.4881540428925282, 'x_max_depth': 4.0, 'x_min_child': 4.0, 'x_reg_lambda': 0.9983795315029678, 'x_subsample': 0.9547128225167194}\n",
    "\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
